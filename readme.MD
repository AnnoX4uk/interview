# interview

Вопросы и ответы для собеседования DevOps

## Какие статус коды ты знаешь?  

### Ответ:  
1xx - информационные. запрос получен, продолжается обработка  
200 - ок  
3хх - перенаправление  
4хх - ошибки на стороне клиента  
400 - bad request - ошибка синтаксиса запроса  
401 - ошибка авторизации (неправильный пароль, просрочился токен)  
403 - доступ запрещен безусловно  
5хх - ошибки на стороне сервера  
500 - внутренняя ошибка сервера  
502 - прокси получил недействительный ответ от настоящего бэкэнда  
504 - таймаут шлюза - прокси не дождался ответа настоящего бэкэнда  

### Почитать: rfc7231  

---  
<br>  

## Какие http методы ты знаешь?

Ответ:
   | Method  | Description                                     |
   |---------|-------------------------------------------------|
   | GET     | Transfer a current representation of the target |
   |         | resource.                                       |
   | HEAD    | Same as GET, but only transfer the status line  |
   |         | and header section.                             |
   | POST    | Perform resource-specific processing on the     |
   |         | request payload.                                |
   | PUT     | Replace all current representations of the      |
   |         | target resource with the request payload.       |
   | DELETE  | Remove all current representations of the       |
   |         | target resource.                                |
   | CONNECT | Establish a tunnel to the server identified by  |
   |         | the target resource.                            |
   | OPTIONS | Describe the communication options for the      |
   |         | target resource.                                |
   | TRACE   | Perform a message loop-back test along the path |
   |         | to the target resource.                         |

---  
<br>  

## Что такое CORS?

Это когда запрашиваемый ресурс содержит ссылку на объект на другом ресуре.
Например при обращении к сайту по https он содержит картинки ссылающиеся  по http.   
При загрузке стреницы елси у ресурсов разные (схема / FQDN / port) то загрузка будет заблокирована CORS политиками.
Необходима передача заголовка acess-control-allow-origin: * (или источник которому разрешен доступ)  

CORS запросы могут быть простыми и сложными.
Признаки сложности запроса:
- методы отличные от GET, POST, или HEAD
- запрос включает заголовки отличные от Accept, Accept-Language или Content-Language
- запрос имеет значение заголовка Content-Type отличное от application/x-www-form-urlencoded, multipart/form-data, или text/plain.

Сложные запросы предваряются prflight запросами с методом options
В ответ на который браузеру необходимо получиь заголовки:  
  * Access-Control-Allow-Methods, который указывает на то, какие методы поддерживаются URL-ом ответа в контексте CORS протокола.  
  * Access-Control-Allow-Headers, который указывает, на то, какие заголовки поддерживаются URL-ом ответа в контексте CORS протокола.  
  * Access-Control-Max-Age, который указывает число секунд (5 по умолчанию) и это значение соответствует периоду, на который предоставляемая заголовками   Access-Control-Allow-Methods и Access-Control-Allow-Headers информация может быть кэширована.

---  
<br>  

## Что такое TLS-SNI
Server Name Indication - расширение протокола TLS, аналог заголовка host при установлении https соединения. Т.е. сервер должен как то узнать какой сертификат ему отдать на запрос clientHello. Из этого заголовка он и будет понимать.


---  
<br>  

## Отличия HTTP1.0, HTTP1.1 и HTTP2

### HTTP1.0
- не поддерживал заголовок HOST
- для каждого запроса открывалось отдельное соединение

### HTTP1.1
- поддерживает постоянные соединения
- для нескольких запросов может быть использовано одно соединение
- поддержка метода options 

### HTTP2.0
- поддержка TLS
- передача в бинарном виде, экономит трафик
- нет проблем с кодировкой
- поддержка технологии server push
- мультиплексирование запросов на одном соединении TCP

### HTTP3.0
На стадии черновика, но уже поддерживается несколькими браузерами. Основан на использовании QUIC - экспериментальном протоколе транспортного уровня от компании Google

---  
<br>  

## Алгоритмы балансировки

- Round robin
- Round robin с весами для upstreams
- IP hash
- sticky session
- least connections

---  
<br>  

## Журналируемые файловые системы

Запись данных на диск производится отдельным постоянно работающим и независимым процессом. Изменение / создание одного файла может требовать нескольких фактических операций записи. Для ускорения, такие операции выполняются транзанкциями, при потере питания в середине транзанкции целостность данных нарушается. 
Для обеспечения большей согласованности используется журналирование, когда операции записи перед непосредственно записью на диск сначала скидываются в журнал (тоже на диск). При загрузке проверяется соответствие журнала и состояния.  
Журнал представляет из себя кольцевой буфер, который при наполнении перезаписывается (место не кончится, бесконечно не растет).  
Пример журналируемых файловых систем: ext3, ext4, xfs  
Режимы журналирования:
- режим обратной связи writeback - журналируются только метаданные;
- упорядоченный  ordered - журналируются метаданные синхронно относительно данных
- режим данных journal -  журналируются данные и метаданные
---  
<br>  

## Принцип COW

Копирование при записи - ускоряет производительность. Суть в том, что фактическое копирование будет произведено только если будет меняться содержимое, а если нет - то будет передан указатель на то же фактическое расположение данных.
Преимущества: 
- быстрее работа
- экономия места - дедубликация данных
- можно делать быстрые snapshots

---  
<br>  

## CAP теорема  

Consistency - Availability - Patition tolerance  
В ограниченный период времени можно обеспечивать только два из трех свойств  
Примеры:  
CA  - реляционные базы MySQL, Postgres  
CP  - HBASE, mongodb, redis  
AP  - Cassandra, Kafka  

---  
<br>  

## Какие планировщики IO есть. Как посмотреть

### Актуальные планировщики ввода вывода:
- mq-deadline — реализация планировщика deadline с использованием blk-mq. Этот планировщик подходит для большинства случаев, но особенно для тех, в которых операции записи в основном асинхронны. Планировщик mq-deadline сортирует запросы ввода-вывода в очереди на чтение или запись, а затем планирует их выполнение в возрастающем порядке адресации логических блоков (LBA).  
- kyber — планировщик, основанный на методах активного управления очередями, используемых для сетевой маршрутизации. Реализация основана на "токенах", которые служат механизмом ограничения запросов. Используется две очереди запросов — на запись и на чтение. kyber отдает приоритет запросам на чтение перед запросами на запись. Реализация алгоритма относительно проста и считается эффективной для NVME, SSD или других устройств с низкой задержкой.  
- bfq (Budget Fair Queuing) — основан на алгоритме от CFQ, но содержит улучшения. В конфигурации по умолчанию он больше нацелен на обеспечение минимальной задержки, а не на достижение максимальной пропускной способности. Этот планировщик обладает относительно высокими расходами на операцию, поэтому он не идеален для устройств с медленными процессорами или устройствами ввода-вывода с высокой пропускной способностью.  
- none – планировщик ввода-вывода без операций с несколькими очередями. Не переупорядочивает запросы и имеет минимальные расходы. Идеально подходит для быстрых устройств произвольного ввода-вывода, таких как SSD или NVME.  

### Устаревшие
noop, CFQ, Deadline

### Посмотреть
```bash
$ cat /sys/block/nvme0n1/queue/scheduler
[none] mq-deadline 
```  

Изменить однократно: через этот же файл.  
Для постоянного изменения потребуется создавать правило в /etc/udev/rules.d где указать какой планировщик применять к какому типу дисков.  

---  
<br>  

## Link-local address
Link-Local Address — адреса сети, предназначеные только для коммуникаций в пределах одного сегмента местной сети. Они позволяют обращаться к хостам, не используя общий префикс адреса.  
Маршрутизаторы не будут отправлять пакеты с адресами link-local.  
Адреса link-local часто используютя автоматического конфигурирования сетевого адреса, в случаях, когда внешние источники информации об адресах сети недоступны.  
Пример использования link-local адресов — автоматическое конфигурирование IP-адресов, используемое в IPv4 и IPv6.  
Адреса IPv4 в диапазоне от 169.254.1.0 до 169.254.254.255 назначаются ОС хоста автоматически в случае недоступности других источников информации, например сервера DHCP.

---  
<br>  

## Отличия OSPF и BGP

Протоколы маршрутизации делятся на внешние протоколы (BGP) и внутренние (OSPF и RIP). Внешние протоколы маршрутизируют трафик среди автономных систем, грубо говоря, подсети провайдеров объединяют внешние протоколы, объединенные внешним маршрутизатором. А внутренние протоколы маршрутизации изучают сеть с помощью других протоколов, таких как OSPF или RIP (чаще всего используют OSPF). 

OSPF — это протокол внутреннего шлюза, который чаще всего используется в локальной сети предприятия. OSPF обычно считается более простым в развёртывании и управлении. Хранит информацию о соседних маршрутизаторах  

BGP был разработан для обмена информацией о маршрутизации между разрозненными сетями, известными как автономные системы AS. Хранит информацию об "интернете"    

Отличие по времени сходимости - OSPF быстрее  
По потреблению ресурсов - OSPF нужно больше для вычислений, требования к ресурсам у BGP определяется размером таблицы

---
<br>

## Кафка партиции  

Информация в Кафка хранится в Топиках. Те, в свою очередь, разделны на 1 и более партиций. Т.о. чтение топика может происходить из нескольких партиций одновременно. Записи с одинаковыми ключами всегда попадают в одну и туже партицию. Партиции реплицируются, каждая реплика хранится на отдельном брокере. На запись всегда работает только одна реплика партиции - она называется лидер. Остальные реплики партиций называются фолловеры. Когда продюсер хочет произвести запись, он обращается к брокерам и запрашивает метаданные, по которым определяет лидера. Консьюмеры объединяются в группы. Для группы кафка хранит значение оффсета - того положения в логе с данными которое члены группы для данной партиции уже считали. Партиции распределяются между членами консьюмер группы. Одну и ту же партицию будет читать только один член группы. Для добавления нового члена консьюмер группы нужно будет создать новую партицию если их количество менее количества членов группы  

---  
<br>  

## default liveness probe in kubernetes

По умолчанию кубернетес проверяет состояние процесса с pid 1 контейнера.

---
<br>  

## Startup, Readiness, Liveness probes. В чем отличие startup от readiness probe?
  
  Readines probe это про траффик (добавление в объект endpoints)  
  Startup probe позволяет делать probe отложенно

    Startup probes: These probes verify whether an application within a container has started. It is only executed at startup, and if a container fails this probe, the container is killed and follows the restartPolicy for the pod. You can configure startup probes in the spec.containers.startupProbe attribute for the pod configuration. A primary motivation for startup probes is that some legacy applications require additional startup time when first initialized, which can make setting liveness probe parameters tricky. When configuring a startupProbe, use the same protocol as the application and ensure the failureThreshold * periodSeconds is enough to cover the worst case startup time. 

    Readiness probes: These probes continuously verify whether a container is ready to serve requests. If the probe returns a failed state, Kubernetes removes the IP address for the pod from the endpoints of all services. Readiness probes enable developers to instruct Kubernetes that a running container should not receive traffic until additional tasks are completed, such as loading files, warming caches, and establishing network connections. You can configure a readiness probe in the spec.containers.readinessProbe attribute for the pod configuration. These probes run periodically as defined by the periodSeconds attribute.

    Liveness probes: These probes help you evaluate whether an application that is running in a container is in a healthy state. If not, Kubernetes kills the container and attempts to redeploy it. These are useful when you want to ensure your application is not deadlocked or silently unresponsive. You can configure liveness probes in the spec.containers.livenessProbecode> attribute of the pod configuration. Like readiness probes, liveness probes also run periodically. We will look at their details and configuration options below.  

---  
<br>  

## Какие namespace есть

их семь:  
* PID - ID процесса в контейнере != ID процесса на хосте  
* network когда запускаем контейнер с хостовой сетью:   
  `$ docker run --net=host nginx` - не создаем новый network namespace  
* mount - изолируют ресурсы файловых систем  **/proc/$pid/mounts**  

  для разных mount namespace можно смонтировать корневую фс "/" в разных местах
  в контейнерах, например, когда мы основываем образ на alpine - образ предоставляет минимальную корневую фс с минимально необходимыми системными файлами и это монтируется как корень. В результате в нэймспейсе контейнера можно безопасно сделать `$ rm -rf /`
* user - это про UID и GID. В разных user namespace GID/UID одного процесса может быть разным  
  уйти в новый user namespace можно с `$ unshare -U bash`  
  связь UID в разных user namespace происходит через файл маппинга */proc/$pid/uid_map*  
* IPC
* cgroups
* UTS

## Чем отличается загрузка BIOS и UEFI?

---
<br>  

## Каким образом происходит передача управления от init ram disk на жесткий диск?
? file <неразборчиво> init true </неразборчиво>

---
<br>

## Как устанавливается https соединение

1. клиент запрашивает соединение с сервером, отправляет поддерживаемые способы шифрования и "случайное число клиента". Запрашивает сертификат и ключ сервера
2. сервер подтверждает клиенту выбранный способ шифрования и сообщает "случайное число сервера". Сервер отправляет свой публичный ключ и сертификат.
3. клиент проверяет у CA что сертификат действительно принадлежит серверу
4. СА подтверждает соответствие сертификата серверу
5. клиент создает ключ сессии, с его участием генерирует случайную строку по алгоритму Дифи-Хелмана, шифрует ее открытым ключем сервера и отправляет серверу
6. сервер расшифровывает случайную строку своим приватным ключем и восстанавливает по Дифи-Хелману ключ сессии
7. все последующие сообщения шифруются и расшифровываются ключем сессии - синхронное шифрование

---
<br>  

## Какие заголовки передает клиент в http запросе

* Host
* User-Agent 
* Accept

---
<br>

## Уровни консистентности в распределенных БД

(strong , eventual consistency)
- at least one 
- at least two
- all
- quorum

---
<br>

## Read own writes
После операции записи получить именно те же данные, т.е. запрос данных только с того же источника, куда производилась запись

---
<br>

## Что такое IO wait
время, которое система проводит в бездействии, когда в ней имеется хотя бы один процесс, ожидающий окончания операции дискового ввода-вывода

---
<br>  

## Что такое ICMP протокол
Internet Control Message Protocol это протокол третьего уровня, который используется для диагностики проблем со связностью в сети. ICMP помогает определить может ли достичь пакет адреса назначения в установленные временные рамки
### Для чего нужен ICMP - для диагностики проблем со связностью в сети

---
<br>

## Уровни изоляции транзакций 

* read uncommited 
  Низший уровень изоляции. Возможно чтение несогласованных, незакоммиченных данных. На запись блокируется до конца транзакции.

* read committed
  Большинство промышленных СУБД используют по умолчанию. На этом уровне обеспечивается защита от чернового, «грязного» чтения, тем не менее, в процессе работы одной транзакции другая может быть успешно закоммичена. В итоге первая транзакция будет работать с другим набором данных - ситуация «неповторяющегося чтения».

* repeatable read 
  Уровень, при котором читающая транзакция «не видит» изменения данных, которые были ею ранее прочитаны. При этом никакая другая транзакция не может изменять данные, читаемые текущей транзакцией, пока та не окончена.

* serializable 
  Самый высокий уровень изоляции; транзакции полностью изолируются друг от друга. Результат выполнения нескольких параллельных транзакций должен быть таким, как если бы они выполнялись последовательно. Только на этом уровне параллельные транзакции не подвержены эффекту «фантомного чтения».

---
<br>

## Принцип BASE для nosql БД
  * Система обеспечивает базовую доступность (Basic Availability), т. е. каждый запрос будет обязательно завершён, успешно или нет;  
  * Система пребывает в гибком состоянии (Soft-state) — очерёдность записей соблюдать необязательно, реплики могут какое-то время находиться в несогласованном состоянии, а система может самостоятельно изменяться для достижения согласованности;  
  - Все данные всё равно достигнут согласованности (Eventual Consistency).

---
<br>

## Как реализован B-tree индекс. Что это такое?
  B-tree- это алгоритм индексирования. Он основан на идее разделения данных на несколько секций, которые называются узлами дерева. Каждый узел содержит набор ключей и ссылок на дочерние узлы. Поиск значения в B-дереве осуществляется путем последовательного перехода по узлам дерева, начиная с корневого узла, и сравнения искомого ключа с ключами в текущем узле. Этот алгоритм обеспечивает быстрое поиск, вставку и удаление данных, особенно в случае большого объема данных.

---
<br>

## Что такое хэш? Чем отличаются алгоритмы хэширования?

  Хэширование представляет собой преобразование любого объема информации в уникальный набор символов, который присущ только этому массиву входящей информации. Этот набор символов и будет называться хэшем. 
  - разрядность
  - криптостойкость
  - вычислительная сложность
  Примеры некриптостойкий - MD5, криптостойкий SHA256

---
<br>

## Что такое JWT. Из чего состоит
  Это  строка в следующем формате header.payload.signature.
  Предположим, что мы хотим зарегистрироваться на сайте. В нашем случае есть три участника — пользователь **user**, сервер приложения **application server** и сервер аутентификации **authentication server**.  
  Сервер аутентификации будет обеспечивать пользователя токеном, с помощью которого он позднее сможет взаимодействовать с приложением.
  
  Хедер JWT содержит информацию о том, как должна вычисляться JWT подпись. Хедер — это тоже JSON объект, который выглядит следующим образом:
    `header = { "alg": "HS256", "typ": "JWT"}`

  Payload — это полезные данные, которые хранятся внутри JWT. Эти данные также называют JWT-claims (заявки). 
    `payload = { "userId": "b08f86af-35da-48f2-8fab-cef3904660bd" }`

  можно положить много заявок. Существует список стандартных заявок для JWT payload — вот некоторые из них:  
  * iss (issuer) — определяет приложение, из которого отправляется токен  
  * sub (subject) — определяет тему токена  
  * exp (expiration time) — время жизни токена  
  Эти поля могут быть полезными при создании JWT, но они не являются обязательными

  Signature - header и payload кодируется base64, объединяется через точку и шифруется по HMAC-SHA256 c помощью секретного ключа

  1. Пользователь заходит на сервер аутентификации с помощью аутентификационного ключа (это может быть пара логин/пароль, либо ключ от другой учетки).
  2. Затем сервер аутентификации создает JWT и отправляет его пользователю.
  3. Когда пользователь делает запрос к API приложения, он добавляет к нему полученный ранее JWT.  
  4. Когда пользователь делает API запрос, приложение может проверить по переданному с запросом JWT является ли пользователь тем, за кого себя выдает. В этой схеме сервер приложения сконфигурирован так, что сможет проверить, является ли входящий JWT именно тем, что был создан сервером аутентификации:
  Сервер приложения получает секретный ключ от сервера аутентификации во время установки аутентификационных процессов. Поскольку приложение знает секретный ключ, когда пользователь делает API-запрос с приложенным к нему токеном, приложение может выполнить тот же алгоритм подписывания к JWT. Приложение может потом проверить эту подпись, сравнивая ее со своей собственной, вычисленной хешированием. Если подписи совпадают, значит JWT валидный, т.е. пришел от проверенного источника. Если подписи не совпадают, значит что-то пошло не так — возможно, это является признаком потенциальной атаки. Таким образом, проверяя JWT, приложение добавляет доверительный слой (a layer of trust) между собой и пользователем.
  
  Рефреш токен (RT) — эти токены выполняют только одну специфичную задачу — получение нового токена доступа. И на этот раз без сервера авторизации не обойтись. Они долгоживущие, но одноразовые.
  Основной сценарий использования такой: как только старый JWT истекает, то с ним мы уже не можем получить приватные данные, тогда отправляем RT и нам приходит новая пара JWT+RT. С новым JWT мы снова можем обращаться к приватным ресурсам. Конечно, рефреш токен тоже может протухнуть, но случится это не скоро, поскольку живет он намного дольше своего собрата.

## Что такое ServiceMesh и istio

ServiceMesh - парадигма организации сетевого взаимодействия микросервисов. Когда монолит разбивается на микросервисы, возникает несколько проблем: как организовать эффективную коммуникацию этих микросервисов. Парадигма сервис мэш заключается в том, что для каждого микросервиса будет внедрен прокси, который будет перехватывать и перенаправлять трафик. Попутно на этом же прокси может быть организовано терминирование tls, сбор метрик, трейсов. Исользование servicemesh позволяет организовать канареечное обновление микросервисов, когда только часть клиентов будет направляться на новую версию приложения.

Самой популярной реализацией servicemash в kubernetes считается istio. Он состоит из своего controlplane на istiod, своего ingress-gateway для кластера. 
По выставлению специальных лэйблов 
sidecar.istio.io/inject="true" - для pod
istio-injection=enabled - для для ns
или через инструмент командной строки istioctl
и можно активировать инъекцию проксей envoy как сайдкаров к подам микросервисов 

---
<br>

## RED, USE, 4 golden signals

Requests
Errors
Duration

Utilisation
Saturation
Errors

Latency
Traffic
Errors
Saturation

---
<br>

## Бэкапы и восстановление postgresql утилита rman
Специфично для oracle. не буду учить пока явно не потребуется с этим работать  

---
<br>

## Чем отличается level 0 бэкап от level 1?
level 0 - full backup - снэпшот
level 1 - increnmental 
От чего берется разница при incremental backup - с времени последнего snapshot (полного бэкапа) до момента снятия инкрементального  

---
<br>

## PGbouncer - для чего нужен
Пулинг соединений
connection pool - разделение коннектов по типу write и read - при помощи pgbouncer невозможно  

---
<br>

## Синхронная / Асинхронная репликация
Синхронная репликация - изменения записываются в WAL хотябы одного слейва, только после этого фиксируются в на мастере. Преимущество - надежность 
Асинхронная репликация - изменения сначала применяются на мастере, затем WAL отправляется на реплики. Преимущество - скорость.  

---
<br> 

## Миграции БД 

### php - на скриптах на lravel `$ php artisan migrate`  

### java 
liquibase в java как работает как понимает что нужно добавлять только новые   
- происходит сверка с таблицей databaseChangelog от changeset считаются хэши и хранятся в таблице. Если хеш в таблице есть, то changeset уже мигрировался

При первом запуске миграции Liquibase или Flyway создает таблицу в схеме базы данных для отслеживания примененных changeset и дальше работает с ней автоматически. Если изменение уже применялось, повторного выполнения не будет.

---
<br>

## Большое количество сервисов - много параллельных коннектов. Какая лучше конфигурация postgress. Max Connect параметр?
Отмасштабировать горизонтально и читающие запросы отправлять на реплики

---
<br>

## Есть логин пароль, IP, посмотреть что есть на сервере. как осмотреться на машине?

/var/log/
dmesg - логи ядра, 
логи контейнеров на хосте
количество inod
iostat
top
lsblk
fstab
ss -p

как посмотреть какие открыты tcp сессии: lsof -i TCP

---
<br> 

## Как работает starce?

Подробный ответ: на [Хабре](https://habr.com/ru/companies/badoo/articles/493856/)  
Перехватывает syscalls программы переданной как аргумент.  
strace отслеживает не только syscalls но и передаваемые процессу сигналы.  
По дефолту вывод программы и вывод от strace будут смешаны.  
Можно отфильтровать поток системных вызовов в файл через ключ о:  
```bash
$ strace -o strace.log <комманда для перехвата>
```  
отслеживать конкретный вызов можно через флаг е:
```bash
$ strace -e trace=write echo "hello"
write(1, "hello\n", 6hello
)                  = 6
+++ exited with 0 +++
```
Или исключить некоторые вызовы через `-o trace=\!<syscall_name>`
Подцепиться к уже работающему процессу можно через флаг `- p <PID>`
Отслеживать вызовы не только родительского, но и дочерних процессов можно через флаг `- f`. В каждой строке вывода будет указываться PID процесса к которому строка относится. 
Можно отслеживать обращения к конкретным файлам, а не дескрипторы, например от вызовов write, через флаг `-y`.  
Можно отслеживать вызовы только связанные с обращением к определенному файлу через `-P<путь к файлу>`.  

---
<br>

## аналоги strace
* perf  - утилита, легковесная альтернатива strace  
* framegraphs

---
<br>

## Посмотреть трафик по некоторым интерфейсам. проснифать трафик?
tcpdump -i <eth>  
wireshark текстовый - tshark

---
<br>

## Load Average 
Характеризует очередь процессов на выполнение. Считаются активные процессы в состояниях R и D.  
треды от процессов go или java тоже будут влиять на очередь

---
<br>

## Как завершить процесс
kill -l
|  #|signal     |  #|signal     |  #|signal     |  #|signal     |  #|signal     |
|--:|:----------|--:|:----------|--:|:----------|--:|:----------|--:|:----------|
| 1)|SIGHUP     | 2)|SIGINT     | 3)|SIGQUIT    | 4)|SIGILL     | 5)|SIGTRAP    |
| 6)|SIGABRT    | 7)|SIGBUS     | 8)|SIGFPE     | 9)|SIGKILL    |10)|SIGUSR1    |
|11)|SIGSEGV    |12)|SIGUSR2    |13)|SIGPIPE    |14)|SIGALRM    |15)|SIGTERM    |
|16)|SIGSTKFLT  |17)|SIGCHLD    |18)|SIGCONT    |19)|SIGSTOP    |20)|SIGTSTP    |
|21)|SIGTTIN    |22)|SIGTTOU    |23)|SIGURG     |24)|SIGXCPU    |25)|SIGXFSZ    |
|26)|SIGVTALRM  |27)|SIGPROF    |28)|SIGWINCH   |29)|SIGIO      |30)|SIGPWR     |
|31)|SIGSYS     |34)|SIGRTMIN   |35)|SIGRTMIN+1 |36)|SIGRTMIN+2 |37)|SIGRTMIN+3 |
|38)|SIGRTMIN+4 |39)|SIGRTMIN+5 |40)|SIGRTMIN+6 |41)|SIGRTMIN+7 |42)|SIGRTMIN+8 |
|43)|SIGRTMIN+9 |44)|SIGRTMIN+10|45)|SIGRTMIN+11|46)|SIGRTMIN+12|47)|SIGRTMIN+13|
|48)|SIGRTMIN+14|49)|SIGRTMIN+15|50)|SIGRTMAX-14|51)|SIGRTMAX-13|52)|SIGRTMAX-12|
|53)|SIGRTMAX-11|54)|SIGRTMAX-10|55)|SIGRTMAX-9 |56)|SIGRTMAX-8 |57)|SIGRTMAX-7 |
|58)|SIGRTMAX-6 |59)|SIGRTMAX-5 |60)|SIGRTMAX-4 |61)|SIGRTMAX-3 |62)|SIGRTMAX-2 |
|63)|SIGRTMAX-1 |64)|SIGRTMAX   |   |           |   |           |   |           |

k|ll -9  <PID>  -> ядру  
kill -15 <PID>  -> процессу для gracefull shutdown. Есть таймаут

Particularly useful signals include HUP, INT, KILL, STOP, CONT, and 0.   
kill -1  <PID>  
kill -2  <PID>  
kill -19 <PID>  
kill -18 <PID>  

---
<br>

## Интерпретация вводимых команд оболочки
|№ п/п|команда                |как будет интерпретировано                                                |
|----:|:----------------------|:-------------------------------------------------------------------------|
|1    |command1 \&\& command2 |Выполнить command2 только если command1 вернула 0                         |
|2    |command1 \& command2   |Выполнение command1 отправить в фон (bg) и сразу выполнить command2 в (fg)|
|3    |command1 \; command2   |Выполнить команды последовательно вне зависимости от результата первой    | 
|4    |command1 \|\| command2 |Выполнить command1, если она вернет не 0, выполнить command2              |
|5    |command1 \| command2   |Пайп. Передать stdout command1 в stadin command2                          |
|6    |command1 command2      |Выполнить command1 с аргументом 'command2'                                |

---
<br>

## Что делают controller managers в k8s? Как посмотреть какие есть controller-managers? 
При классической установке argo-cd появляется несколько (3) контроллеров. Для чего эти контроллеры нужны?
Для  некастомных ресурсов в k8s имеются controller-managers которые отслеживают состояние этих ресурсов и управляют ими через api-server
Для кастом ресурсов необходимо предоставить свои кастом контроллеры. У argo-cd это application group и application controller manager  

---
<br> 

## В чем преимущество deployment перед replicaset
Более удобная абстракция над replicaset позволяет реализовать стратегию deployment
  - rolling update 
  - recreate  
добавляет версионирование  

---
<br> 

## helm atomic / wait
**--wait** - перед внесением записи о релизе как successfull будет ожидать перехода подов в состояние **ready** но не более чем указано в параметре **--timeout** (default 5m0s)   
**--atomic** - откатит изменения если в upgrade случится ошибка  
  при использовании **--atomic** флаг **--wait** устанавливается автоматически 

---
<br>

## Как передать конфигурацию nginx

  - через configmap / secret
  - через env
  - через init container / volume

---
<br>

## Python декораторы
Оборачивает вызов функции другой функцией.  
Декоратор принимает функцию в качестве аргумента и возвращает функцию.  

### Как сохранить тип данных функции? Сохранить строки документации (doc string)?
использовать **functools.wraps()** для декорирования wrapper функции самого декоратора

---
<br>

## Исключения и как с ними работать в python
try 
except  - только в исключитьельной ситуации
finally - всегда

Как обрабатывать любую ошибку?
смотреть в сторону наследования, кто родитель классов групп ошибок и перехватывать его

Перехватить ошибку 3й вложенной функции в 1ой (родительской)?
поднять свою ошибку в 3й функции при помощи raise и обработать в 1ой
```python
try:
  raise Exception("Some exception")
except Exception as e:
  print("Exception " + str(e))
```

---
<br>

## Crowd управление польззователями это?
Это SSO сервис для управления доступом пользователей к веб приложениям

---
<br>

## truncate через дескриптор

открытый дескриптор файла, например если известен процесс который имеет в него дескриптор, то можно пролистать: 
```bash
 $ ls -lA /proc/<pid>/fd
```
или по имени файла:
```bash
$ lsof <путь к файлу>
COMMAND      PID    USER            FD             TYPE  DEVICE  SIZE/OFF  NODE    NAME
<команда>    <PID>  <пользователь>  <дескриптор>   REG   259,5   <размер>  <inode> <путь к файлу>
```
например, это дескриптор FD=4, то можно обрезать файл до нуля байт:  
```bash
$ truncate -s 0 /proc/<pid>/fd/4
```

---
<br>

## inode файлов и директорий- uid 
inode - метаданные о файле - даты созания, модификации, правах, в каком блоке размещаются данные. Эта информация хранится в inode. В некоторых файловых системах количество inode фиксировано и задается при создании, в других может увеличиваться.
посмотреть количесво свободных inode через **df -i**
inode хранятся в таблице в файловой системе 
посмотреть информации можно через 
```bash
sudo debugfs /dev/<раздел с файловой системой>
stat <2> 
# листинг содержимого:
ls -l <2> 
```
в выводимом результате будет информация по / в т.ч. номер блока файла
корень имеет inode с номером 2

Посмотреть информацию по файловой системе можно командой 
```bash
$ sudo tune2fs -l /dev/nvme0n1p5
tune2fs 1.45.5 (07-Jan-2020)
Filesystem volume name:   <none>
Last mounted on:          /
Filesystem UUID:          <какой-то id>
Filesystem magic number:  0xEF53
Filesystem revision #:    1 (dynamic)
Filesystem features:      has_journal ext_attr resize_inode dir_index filetype needs_recovery extent 64bit flex_bg sparse_super large_file huge_file dir_nlink extra_isize metadata_csum
Filesystem flags:         signed_directory_hash 
Default mount options:    user_xattr acl
Filesystem state:         clean
Errors behavior:          Continue
Filesystem OS type:       Linux
Inode count:              15187968
Block count:              60751872
Reserved block count:     3037593
Free blocks:              24119087
Free inodes:              13383310
First block:              0
Block size:               4096
Fragment size:            4096
Group descriptor size:    64
Reserved GDT blocks:      1024
Blocks per group:         32768
Fragments per group:      32768
Inodes per group:         8192
Inode blocks per group:   512
Flex block group size:    16
Filesystem created:       Tue Mar 15 11:04:34 2022
Last mount time:          Wed Jul 12 08:08:18 2023
Last write time:          Wed Jul 12 08:08:18 2023
Mount count:              718
Maximum mount count:      -1
Last checked:             Sat Jun 25 00:07:37 2022
Check interval:           0 (<none>)
Lifetime writes:          2934 GB
Reserved blocks uid:      0 (user root)
Reserved blocks gid:      0 (group root)
First inode:              11
Inode size:	          256
Required extra isize:     32
Desired extra isize:      32
Journal inode:            8
First orphan inode:       2495490
Default directory hash:   half_md4
Directory Hash Seed:      <hash>
Journal backup:           inode blocks
Checksum type:            crc32c
Checksum:                 0xb08ae7d8
```
какое то количество inodes и blocks могут быть зарезервированы для рута   

---
<br>

## top

память используемая процессом - колонка res
available memory = free + buff/cache

buff/cache - буферная память используемая устройствами ввода-вывода. 
cache - кэш, файлы которые могут быть прочитаны опять.      
Cкинуть буферы и почистить кэш: 
```
root@shamil:~# sync; echo 1 > /proc/sys/vm/drop_caches
```

---
<br>

## Ускорить сетку

* Объединить интерфейсы с помощью утилиты **ifenslave**. Будет создан bond0 который будет агрегировать другие интерфейсы  
* параметры из **/proc/sys/**:  
  /proc/sys/net/ip_local_port_range 
  /proc/sys/fs/file-max

---
<br>

## ACL в линукс

Расширение гранулярности доступа к файлам и папкам - списки контроля доступа  
Для работы с этим потребуется смонтировать файловую систему с поддержкой acl mount  
установка и просмотр правил через команды **setfacl; getfacl**
признак наличия acl на каталоге - символ + после стандартных прав доступа в выводе **ls -l**

---
<br>

## setuid bit работает на bash скрипты?
 - нет. слишком опасно.

---
<br>

## cgroups линукс

Механизм для разграничения доступных процессу ресурсов.  
Память, процессорное время, дисковое пространство  

### Как посмотреть к каким процессам применяется cgroup
по пути /sys/fs/cgroup/<подсистема>/tasks 

---
<br>

## Как увеличить производительность tcp соединения
Через какое количество сегментов отправляется подтверждение о получении

---
<br>

## Где хранятся ip корневых DNS серверов

зашиты в ОС. IP адреса [общеизвестны](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%80%D0%BD%D0%B5%D0%B2%D1%8B%D0%B5_%D1%81%D0%B5%D1%80%D0%B2%D0%B5%D1%80%D1%8B_DNS). Их 13 штук + много реплик отвечающих по anycast

---
<br>

## Кублеты наблюдают за сущностями pods расписанными в etcd через api server
Как запускаются объекты при отправке манифеста с деплойментом:  
![1.png image placeholder](/img/1.png)

---
<br>

## Security context 
может быть настроен в спецификации на уровне pod и на уровне container  
Можно переопределять user , mount volums 



ansible run in parallel: группы в инвентори
сбор фактов: отключить
вместо копирования скриптов в stdin интерпретатора python
поменять ssh клиент у ansible
не дожидаться выполнения task до конца и запускать след

global_vars - приоритеты переменных ansible

конфиги maven 

kv2 - разграничение на чтение секретов и метаданных - при удалении секрета метаданные остаются


как интегрировать доступ в волт из кубера , нужен сервис аккаунт для волта для валидации токена в кубе


approle - метод аутентификации в волте


кэши на nginx


proxy_set_headers -> переопределить хэдеры на таргет


add_header -> переопределить в респонс


401 autorise доступ к метрикам на нодах для prometeus  -  создать сервис nodeport который будет создать кластерную роль с endpoint на который можно стучаться 


сервис дискавери для прометея в кубе на основе аннотаций


как подсчитать какую долю процессовгого времени потребляет контейнер в кубе через rate


set -eo pipefail

# Интервью 07.07.23

## Осмотреться на сервисе через ssh
посмотреть открытые порты: 
lsof -i
netcat -tunapl
ss -tunapl

посмотреть открытые сокеты: 
lsof -i -U

посмотреть трафик:
tcpdump
iftop

## что и как смотреть с iperf 

это генератор трафика, предназначена для проверки скорости и пропускной способности сети. Состоит из клиентской и серверной части. Для игр с этим потребуется 2 компбютера
запускаем как сервер с ключем s  
другой как клиент с ключем c и передаем адрес сервера
для изменения направления можно применять ключ -R  

## sparse files
такие файлы которым выделяется места больше чем фактически можно. Определяется по тому что его использование диска меньше чем его размер  
Через du -sh один размер, а через ls -lh - другой  
искать через find, с параметром форматированного вывода "%S\t%p\n"

## Посмотреть диски
lsblk, fdisk -l

## Статусы процессов

* R - running или runnable
* D - непрерываемый сон. запросил данные и ждет их получения. прервать процесс не получится
* I - бездействующий. не учитывается в load average
* S - спит - ожидает ресурсы которые в данный момент недоступны. после получения ресурсов перейдет в R  
* T/t - остановленный сигналом или отладчиком
* Z - после завершения работы зомби освобождает свои ресурсы, но сохраняется запись в таблице pid. Для удаления записи посылается сигнал родителю процесса. Если родитель не обрабатывает этот сигнал, не освобождает PID по каким то причинам, то процесс остается зомби
Если есть идентификатор родительского зомби-процесса, можно использовать следующую команду для отправки сигнала SIGCHLD родительскому процессу:
```$ kill -s SIGCHLD <Parent PID>```

## helm hooks
подброс новых конфигураций

## helm управляющая структура range, define, helpers
pipelines для модификаций : перевести в верхний регистр, в кавычки провести, использовать default
merge

